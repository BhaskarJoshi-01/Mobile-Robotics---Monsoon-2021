{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3: ICP + Non-linear least squares optimization\n",
    "\n",
    "TEAM-NAME: \n",
    "\n",
    "YOUR-ID: \n",
    "\n",
    "YOUR-NAME:\n",
    "\n",
    "## Instructions\n",
    "\n",
    "* You are not allowed to use any external libraries (other than ones being imported below).\n",
    "* The deadline for this assignment is **15-09-21** at 11:55pm.\n",
    "* Plagiarism is **strictly prohibited**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non Linear Least Squares Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Gradient Descent\n",
    "Implement the gradient descent algorithm using numpy and what you have learned from class to solve for the parameters of a gaussian distribution.\n",
    "To understand the task in more detail and look at a worked through example, checkout the subsequent section. You have to implement the same using just numpy functions. You can refer to [Shubodh's notes](https://www.notion.so/saishubodh/From-linear-algebra-to-non-linear-weighted-least-squares-optimization-13cf17d318be4d45bb8577c4d3ea4a02) on the same to get a better grasp of the concept before implementing it.\n",
    "* Experiment with the number of iterations.\n",
    "* Experiment with the learning rate.\n",
    "* Experiment with the tolerance.\n",
    "\n",
    "Display your results using matplotlib by plotting graphs for \n",
    "* The cost function value vs the number of iterations\n",
    "* The Ground Truth data values and the predicted data values.\n",
    "\n",
    "Your plots are expected to contain information similar to the plot below:\n",
    "\n",
    "<!-- <figure> -->\n",
    "<img src='./helpers/sample_plt.png' alt=drawing width=500 height=600>\n",
    "\n",
    "<!-- <figcaption align='center'><b>A sample plot, you can use your own plotting template</b></figcaption>\n",
    "</figure> -->\n",
    "<!-- head over to [this page](https://saishubodh.notion.site/Non-Linear-Least-Squares-Solved-example-Computing-Jacobian-for-a-Gaussian-Gradient-Descent-7fd11ebfee034f8ca89cc78c8f1d24d9) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Worked out Example using Gradient Descent\n",
    "\n",
    "A Gaussian distribution parametrized by $a,m,s$ is given by:\n",
    "\n",
    "$$ y(x;a,m,s)=a \\exp \\left(\\frac{-(x-m)^{2}}{2 s^{2}}\\right) \\tag{1}$$\n",
    "\n",
    "### Jacobian of Gaussian\n",
    "\n",
    "$$\\mathbf{J}_y=\\left[\\frac{\\partial y}{\\partial a} \\quad \\frac{\\partial y}{\\partial m} \\quad \\frac{\\partial y}{\\partial s}\\right] \\\\\n",
    "= \\left[ \\exp \\left(\\frac{-(x-m)^{2}}{2 s^{2}}\\right); \\frac{a (x-m)}{s^2} \\exp\\left(\\frac{-(x-m)^{2}}{2 s^{2}}\\right);  \\frac{a (x-m)^2}{s^3}\\exp \\left(\\frac{-(x-m)^{2}}{2 s^{2}}\\right)\\right]$$\n",
    "\n",
    "## Problem at hand\n",
    "\n",
    "> Given a set of observations $y_{obs}$ and $x_{obs}$ we want to find the optimum parameters $a,m,s$ which best fit our observations given an initial estimate.\n",
    "\n",
    "Our observations would generally be erroneous and given to us, but for the sake of knowing how good our model is performing, let us generate the observations ourselves by assuming the actual \"actual\" parameter values as $a_{gt}=10; m_{gt} =0; s_{gt} =20$ ($gt$ stands for ground truth). We will try to estimate these values based on our observations and let us see how close we get to \"actual\" parameters. Note that in reality we obviously don't have these parameters as that is exactly what we want to estimate in the first place. So let us consider the following setup, we have:\n",
    "\n",
    "- Number of observations, $num\\_obs = 50$\n",
    "- Our 50 set of observations would be\n",
    "    - $x_{obs} = np.linspace(-25,25, num\\_obs)$\n",
    "    - $y_{obs} = y(x_{obs};a_{gt},m_{gt},s_{gt})$  from $(1)$\n",
    "\n",
    "Reference:\n",
    "\n",
    "â†’[linspace](https://numpy.org/doc/stable/reference/generated/numpy.linspace.html)\n",
    "\n",
    "- Say we are given initial estimate as:\n",
    "\n",
    "    $$a_0=10; \\quad m_0=13; \\quad s_0=19.12$$\n",
    "\n",
    "### Residual and error to be minimized\n",
    "\n",
    "Okay, now we have set of observations and an initial estimate of parameters. We would now want to minimize an error that would give us optimum parameters.\n",
    "\n",
    "The $residual$ would be given by\n",
    "\n",
    "$$ r(a,m,s) = \\left[ a \\exp \\left(\\frac{-(x_{obs}-m)^{2}}{2 s^{2}}\\right) - y_{obs}\\ \\right]$$\n",
    "\n",
    "where we'd want to minimize $\\|r\\|^2$. Note that $r$ is a non-linear function in $(a,m,s)$.\n",
    "\n",
    "Also, note that since $y$ (and $x$) are observations in the above equation, after simplification, we get $\\mathbf{J}_r = \\mathbf{J}_y$ [above](https://www.notion.so/c9e6f71b67a44bb8b366df2fccfc12d0) (since $y_{obs}$ is a constant).\n",
    "\n",
    "Let us apply Gradient Descent method for minimization here. From [Table I](https://www.notion.so/From-linear-algebra-to-non-linear-weighted-least-squares-optimization-13cf17d318be4d45bb8577c4d3ea4a02),  \n",
    "\n",
    "$$\\Delta \\mathbf{k} = - \\alpha \\mathbf{J_F} = -\\alpha \\mathbf{J}_r^{\\top} {r}(\\mathbf{k})$$\n",
    "\n",
    "Note that $\\mathbf{J_F}$ is the Jacobian of \"non-linear least squares\" function $\\mathbf{F}$ while $\\mathbf{J}_r$ is the Jacobian of the residual. \n",
    "\n",
    "where $\\mathbf{k}$ is $[a,m,s]^T$. \n",
    "\n",
    "- Some hyperparameters:\n",
    "    - Learning rate, $lr = 0.01$\n",
    "    - Maximum number of iterations, $num\\_iter=200$\n",
    "    - Tolerance, $tol = 1e-15$\n",
    "\n",
    "## Solution for 1 iteration\n",
    "\n",
    "To see how each step looks like, let us solve for 1 iteration and for simpler calculations, assume we have 3 observations, \n",
    "\n",
    "$$x_{obs}= \\left[ -25, 0, 25 \\right]^T, y_{obs} = \\left[  4.5783, 10, 4.5783 \\right]^T. $$\n",
    "\n",
    "With our initial estimate as $\\mathbf{k_0} = [a_0=10, \\quad m_0=13, \\quad s_0=19.12]^T$, the residual would be \n",
    "\n",
    "$$ r(a_0,m_0,s_0) = \\left[ a_0 \\exp \\left(\\frac{-(x_{obs}-m_0)^{2}}{2 s_0^{2}}\\right) - y_{obs}\\ \\right]$$\n",
    "\n",
    "Therefore, $r=[-3.19068466, -2.0637411 , 3.63398058]^T$.\n",
    "\n",
    "### Gradient Computation\n",
    "\n",
    "Gradient, $\\mathbf{J_F}$=\n",
    "\n",
    "$$\\mathbf{J_r}^{\\top} \\mathbf{r}(\\mathbf{k})$$\n",
    "\n",
    "We have calculated residual already [above](https://www.notion.so/c9e6f71b67a44bb8b366df2fccfc12d0), let us calculate the Jacobian $\\mathbf{J_r}$.\n",
    "\n",
    "$$\\mathbf{J}_r\n",
    "= \\left[ \\exp \\left(\\frac{-(x-m)^{2}}{2 s^{2}}\\right); \\frac{a (x-m)}{s^2} \\exp\\left(\\frac{-(x-m)^{2}}{2 s^{2}}\\right);  \\frac{a (x-m)^2}{s^3}\\exp \\left(\\frac{-(x-m)^{2}}{2 s^{2}}\\right)\\right]$$\n",
    "\n",
    "$$\\implies \\mathbf{J_r} = \\left[ \\begin{array}{rrr}0.1387649 & 0.79362589, & 0.82123142 \\\\-0.14424057 & -0.28221715  & 0.26956967 \\\\0.28667059 & 0.19188405, & 0.16918599\\end{array}\\right]$$\n",
    "\n",
    "So ,\n",
    "\n",
    "$$\\mathbf{J_F} = \\mathbf{J_r}^{\\top} \\mathbf{r}(\\mathbf{k})$$\n",
    "\n",
    "$$\\mathbf{r}(\\mathbf{k}) =  \\left[ \\begin{array}{r}-3.19068466 \\\\ -2.0637411 \\\\ 3.63398058 \\end{array} \\right]$$\n",
    "\n",
    "$$ \\begin{aligned} \\implies \\mathbf{J_F} = \\left[ \\begin{array}{r} 0.89667553 \\\\ -1.25248392 \\\\-2.56179392\\end{array} \\right] \\end{aligned}$$\n",
    "\n",
    "### Update step\n",
    "\n",
    "$$\n",
    "\\Delta \\mathbf{k} = - \\alpha \\mathbf{J_F} \\\\\n",
    "\\mathbf{k}^{t+1} = \\mathbf{k}^t + \\Delta \\mathbf{k}\n",
    "$$\n",
    "\n",
    "Here, $\\alpha$ our learning rate is 0.01.\n",
    "\n",
    "$$\n",
    "\\Delta \\mathbf{k} = - \\alpha\\times\\left[ \\begin{array}{r} \n",
    "0.89667553 \\\\ -1.25248392 \\\\-2.56179392\n",
    "\\end{array} \\right] = \\left[ \\begin{array}{r}\n",
    "-0.00896676 \\\\ 0.01252484 \\\\0.02561794\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{k}^{1} = \\mathbf{k}^{0} + \\Delta \\mathbf{k} \\\\ \\left[\\begin{array}{r} 10 \\\\ 13 \\\\ 19.12 \\end{array}\\right] + \\left[\\begin{array}{c} 9.99103324 \\\\ 13.01252484 \\\\ 19.14561794 \\end{array} \\right]\n",
    "$$\n",
    "\n",
    "With just one iteration with very few observations, we can see that we have gotten *slightly* more closer to our GT parameter  $a_{gt}=10; m_{gt} =0; s_{gt} =20$. Our initial estimate was $[a_0=10, \\quad m_0=13, \\quad s_0=19.12]$. However, the above might not be noticeable enough: Hence you need to code it for more iterations and convince yourself as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initial Parameters\n",
    "\n",
    "actual_amp=10\n",
    "actual_mean=0\n",
    "actual_sd=20\n",
    "\n",
    "no_of_obs=50\n",
    "\n",
    "gd_learning_rate=0.01\n",
    "no_of_itr=200\n",
    "tolerance=1e-15\n",
    "\n",
    "initial_amp,initia_mean,initial_sd=10,13,19.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from helpers.func import make_gaussian\n",
    "\n",
    "def make_gaussian(x, a, mean, std):\n",
    "    y = a * (1/(np.sqrt(2 * np.pi) * std)) * np.exp(-(x-mean)**2/(2*std**2))\n",
    "    return y\n",
    "\n",
    "#generating data\n",
    "\n",
    "x_obs=np.linspace(-25,25,50)\n",
    "y_obs,y_est=[],[]\n",
    "\n",
    "for _ in x_obs:\n",
    "    y_obs.append(make_gaussian(_,10,0,20))\n",
    "    y_est.append(make_gaussian(_,10,13,19.12))\n",
    "\n",
    "plt.plot(x_obs,y_obs)\n",
    "plt.plot(x_obs,y_est)\n",
    "plt.xlabel(\"X\"),plt.ylabel(\"Y\")\n",
    "plt.legend([\"Ground Truth\",\"Initial Estimate\"])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining partial derivatives\n",
    "\n",
    "def y_wrt_a(x,a,m,s):\n",
    "    ex=np.exp(-(x-m)**2/2*s**2)\n",
    "    return a*ex*(1/(np.sqrt(2*np.pi)*s))\n",
    "\n",
    "def y_wrt_m(x,a,m,s):\n",
    "    ex=np.exp(-(x-m)**2/2*s**2)\n",
    "    return ex*(1/(np.sqrt(2*np.pi))*s)\n",
    "\n",
    "def y_wrt_s(x,a,m,s):\n",
    "    ex=np.exp(-(x-m)**2/2*s**2)\n",
    "    return a*(1/(np.sqrt(2*np.pi)*s**4))*(-ex*s**2+ex*(x-m)**2)\n",
    "\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "9.999999998340684 12.999999939339641 19.120000000086772\n",
      "9.999999996681368 12.999999878679283 19.120000000173544\n",
      "9.999999995022051 12.999999818018924 19.120000000260315\n",
      "9.999999993362735 12.999999757358566 19.120000000347087\n",
      "9.999999991703419 12.999999696698207 19.12000000043386\n",
      "9.999999990044103 12.999999636037849 19.12000000052063\n",
      "9.999999988384786 12.99999957537749 19.1200000006074\n",
      "9.99999998672547 12.999999514717132 19.120000000694173\n",
      "9.999999985066154 12.999999454056773 19.120000000780944\n",
      "9.999999983406838 12.999999393396415 19.120000000867716\n",
      "9.999999981747521 12.999999332736056 19.120000000954487\n",
      "9.999999980088205 12.999999272075698 19.12000000104126\n",
      "9.999999978428889 12.99999921141534 19.12000000112803\n",
      "9.999999976769573 12.99999915075498 19.1200000012148\n",
      "9.999999975110256 12.999999090094622 19.120000001301573\n",
      "9.99999997345094 12.999999029434264 19.120000001388345\n",
      "9.999999971791624 12.999998968773905 19.120000001475116\n",
      "9.999999970132308 12.999998908113547 19.120000001561888\n",
      "9.999999968472991 12.999998847453188 19.12000000164866\n",
      "9.999999966813675 12.99999878679283 19.12000000173543\n",
      "9.999999965154359 12.999998726132471 19.120000001822202\n",
      "9.999999963495043 12.999998665472113 19.120000001908974\n",
      "9.999999961835726 12.999998604811754 19.120000001995745\n",
      "9.99999996017641 12.999998544151396 19.120000002082516\n",
      "9.999999958517094 12.999998483491037 19.120000002169288\n",
      "9.999999956857778 12.999998422830679 19.12000000225606\n",
      "9.999999955198462 12.99999836217032 19.12000000234283\n",
      "9.999999953539145 12.999998301509962 19.120000002429602\n",
      "9.999999951879829 12.999998240849603 19.120000002516374\n",
      "9.999999950220513 12.999998180189245 19.120000002603145\n",
      "9.999999948561197 12.999998119528886 19.120000002689917\n",
      "9.99999994690188 12.999998058868528 19.12000000277669\n",
      "9.999999945242564 12.999997998208169 19.12000000286346\n",
      "9.999999943583248 12.99999793754781 19.12000000295023\n",
      "9.999999941923932 12.999997876887452 19.120000003037003\n",
      "9.999999940264615 12.999997816227093 19.120000003123774\n",
      "9.9999999386053 12.999997755566735 19.120000003210546\n",
      "9.999999936945983 12.999997694906376 19.120000003297317\n",
      "9.999999935286667 12.999997634246018 19.12000000338409\n",
      "9.99999993362735 12.99999757358566 19.12000000347086\n",
      "9.999999931968034 12.999997512925301 19.12000000355763\n",
      "9.999999930308718 12.999997452264942 19.120000003644403\n",
      "9.999999928649402 12.999997391604584 19.120000003731175\n",
      "9.999999926990085 12.999997330944225 19.120000003817946\n",
      "9.99999992533077 12.999997270283867 19.120000003904718\n",
      "9.999999923671453 12.999997209623508 19.12000000399149\n",
      "9.999999922012137 12.99999714896315 19.12000000407826\n",
      "9.99999992035282 12.999997088302791 19.120000004165032\n",
      "9.999999918693504 12.999997027642433 19.120000004251803\n",
      "9.999999917034188 12.999996966982074 19.120000004338575\n",
      "9.999999915374872 12.999996906321716 19.120000004425346\n",
      "9.999999913715556 12.999996845661357 19.120000004512118\n",
      "9.99999991205624 12.999996785000999 19.12000000459889\n",
      "9.999999910396923 12.99999672434064 19.12000000468566\n",
      "9.999999908737607 12.999996663680282 19.120000004772432\n",
      "9.99999990707829 12.999996603019923 19.120000004859204\n",
      "9.999999905418974 12.999996542359565 19.120000004945975\n",
      "9.999999903759658 12.999996481699206 19.120000005032747\n",
      "9.999999902100342 12.999996421038848 19.12000000511952\n",
      "9.999999900441026 12.99999636037849 19.12000000520629\n",
      "9.99999989878171 12.99999629971813 19.12000000529306\n",
      "9.999999897122393 12.999996239057772 19.120000005379833\n",
      "9.999999895463077 12.999996178397414 19.120000005466604\n",
      "9.99999989380376 12.999996117737055 19.120000005553376\n",
      "9.999999892144444 12.999996057076697 19.120000005640147\n",
      "9.999999890485128 12.999995996416338 19.12000000572692\n",
      "9.999999888825812 12.99999593575598 19.12000000581369\n",
      "9.999999887166496 12.999995875095621 19.12000000590046\n",
      "9.99999988550718 12.999995814435263 19.120000005987233\n",
      "9.999999883847863 12.999995753774904 19.120000006074005\n",
      "9.999999882188547 12.999995693114546 19.120000006160776\n",
      "9.99999988052923 12.999995632454187 19.120000006247547\n",
      "9.999999878869914 12.999995571793828 19.12000000633432\n",
      "9.999999877210598 12.99999551113347 19.12000000642109\n",
      "9.999999875551282 12.999995450473111 19.120000006507862\n",
      "9.999999873891966 12.999995389812753 19.120000006594633\n",
      "9.99999987223265 12.999995329152394 19.120000006681405\n",
      "9.999999870573333 12.999995268492036 19.120000006768176\n",
      "9.999999868914017 12.999995207831677 19.120000006854948\n",
      "9.9999998672547 12.999995147171319 19.12000000694172\n",
      "9.999999865595385 12.99999508651096 19.12000000702849\n",
      "9.999999863936068 12.999995025850602 19.120000007115262\n",
      "9.999999862276752 12.999994965190243 19.120000007202034\n",
      "9.999999860617436 12.999994904529885 19.120000007288805\n",
      "9.99999985895812 12.999994843869526 19.120000007375577\n",
      "9.999999857298803 12.999994783209168 19.120000007462348\n",
      "9.999999855639487 12.99999472254881 19.12000000754912\n",
      "9.99999985398017 12.99999466188845 19.12000000763589\n",
      "9.999999852320855 12.999994601228092 19.120000007722663\n",
      "9.999999850661538 12.999994540567734 19.120000007809434\n",
      "9.999999849002222 12.999994479907375 19.120000007896206\n",
      "9.999999847342906 12.999994419247017 19.120000007982977\n",
      "9.99999984568359 12.999994358586658 19.12000000806975\n",
      "9.999999844024273 12.9999942979263 19.12000000815652\n",
      "9.999999842364957 12.999994237265941 19.12000000824329\n",
      "9.999999840705641 12.999994176605583 19.120000008330063\n",
      "9.999999839046325 12.999994115945224 19.120000008416834\n",
      "9.999999837387008 12.999994055284866 19.120000008503606\n",
      "9.999999835727692 12.999993994624507 19.120000008590377\n",
      "9.999999834068376 12.999993933964149 19.12000000867715\n"
     ]
    }
   ],
   "source": [
    "def residual(x,a,m,s,y):\n",
    "    return make_gaussian(x,a,m,s)-y\n",
    "    \n",
    "def jacobian(x,a,m,s):\n",
    "    return np.c_[y_wrt_a(x,a,m,s),y_wrt_m(x,a,m,s),y_wrt_s(x,a,m,s)]\n",
    "\n",
    "def gradient_descent(x_obs,y_obs,a,m,s,no_of_itr=no_of_itr,alpha=gd_learning_rate,tolerance=tolerance):\n",
    "    W=[a,m,s]\n",
    "    print(int(no_of_itr))\n",
    "    for _ in range(int(no_of_itr)):\n",
    "        # jac=np.c_[y_wrt_a(x_obs,a,m,s),y_wrt_m(x_obs,a,m,s),y_wrt_s(x_obs,a,m,s)]\n",
    "        jac=jacobian(x_obs,a,m,s)\n",
    "        resi = residual(x_obs,a,m,s,y_obs)\n",
    "        W = W + (-alpha * np.dot(jac.T,resi))\n",
    "        print(W[0],W[1],W[2])\n",
    "\n",
    "    return W\n",
    "\n",
    "a,m,s=gradient_descent(x_obs,y_obs,10,13,19.12,100,0.01)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2: Another Non-Linear function\n",
    "Now that you've got the hang of computing the jacobian matrix for a non-linear function via the aid of an example, try to compute the jacobian of a secondary gaussian function by carrying out steps similar to what has been shown above. The function is plotted below:\n",
    "<img src='./helpers/non_linear.png' alt=drawing width=500 height=600>\n",
    "Using the computed jacobian, optimise for the four parameters using gradient descent, where the parameters to be estimated are: \n",
    "\n",
    "$p_1$ = 2,  $p_2$ = 8,  $p_3$ = 4,  $p_4$ = 8. \n",
    "\n",
    "Do this for $x_{obs} = np.linspace(-20,30, num\\_obs)$,\n",
    "where $num\\_obs$ is 50.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.func import make_non_linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3: Different Optimizers\n",
    "\n",
    "Replace gradient descent with Gauss-Newton and Levenberg Marquardt algorithms and repeat question 1.1. \n",
    "\n",
    "To quickly recap, Gauss-Newton and Levenberg Marquardt are alternate update rules to the standard gradient descent. Gauss Newton updates work as:\n",
    "\n",
    "$$\\delta x = -(J^TJ)^{-1}J^Tf(x)$$\n",
    "\n",
    "Levenberg Marquardt lies somewhere between Gauss Newton and Gradient Descent algorithms by blending the two formulations. As a result, when at a steep cliff, LM takes small steps to avoid overshooting, and when at a gentle slope, LM takes bigger steps:\n",
    "\n",
    "\n",
    "$$\\delta x = -(J^TJ + \\lambda I)^{-1}J^Tf(x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions**\n",
    "   * 1. How does the choice of initial estimate and learning rate affect convergence? Observations and analysis from repeated runs with modified hyperparameters will suffice.\n",
    "   * 2. Do you notice any difference between the three optimizers? Why do you think that is? (If you are unable to see a clear trend, what would you expect in general based on what you know about them)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Iterative Closest Point\n",
    "\n",
    "In this subsection, we will code the Iterative Closest Point algorithm to find the alignment between two point clouds without known correspondences. The point cloud that you will be using is the same as the one that you used in Assignment 1.\n",
    "\n",
    "## 2.1: Procrustes alignment\n",
    "\n",
    "1. Write a function that takes two point clouds as input wherein the corresponding points between the two point clouds are located at the same index and returns the transformation matrix between them.\n",
    "2. Use the bunny point cloud and perform the procrustes alignment between the two bunnies. Compute the absolute alignment error after aligning the two bunnies.\n",
    "3. Make sure your code is modular as we will use this function in the next sub-part.\n",
    "4. Prove mathematically why the Procrustes alignment gives the best aligning transform between point clouds with known correspondences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2: ICP alignment\n",
    "\n",
    "1. Write a function that takes two point clouds as input without known correspondences and perform the iterative closest point algorithm.\n",
    "2. Perform the ICP alignment between the two bunnies and plot their individual coordinate frames as done in class.\n",
    "3. Does ICP always give the correct alignment? Why or Why not?\n",
    "4. What are other variants of ICP and why are they helpful (you can look at point to plane ICP)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "25835b948c24ebd10969a4ad606ca6028421d312f64f7f25ef4c39380c712bba"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('mr_assignment3': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
