{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4\n",
    "\n",
    "Approximate time needed: 6-7 hours\n",
    "    \n",
    "## DLT and Epipolar Lines\n",
    "\n",
    "The goal of this assignment is to aid your understanding of the Direct Linear Transform as well as Epipolar geometry.\n",
    "\n",
    "For the first part of the assignment you will find correspondences between 2D-3D points and estimate the P Matrix. You will then be required to estimate Camera Parameters from this P matrix.\n",
    "\n",
    "The second part of this assignment will require you to construct epipolar lines on two corresponding images.\n",
    "\n",
    "The third part of this assignment will require you to use camera intrinsics to estimate the bounding box of a car."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 4.1 Generating Correspondences\n",
    "The first step to perform DLT is to generate correspondences. The cell below opens a new window. Clicking anywhere on the image should give you the pixel location of the image. Once you're done clicking, close the image window. The cell after displays the points you have clicked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After generating pixel locations, you have to generate the corresponding world points. You have the freedom to chose which point you want as origin. You can consider each side as 4 units.\n",
    "\n",
    "Ensure that the ordering of your points matches the ordering of image points. Keep track of the sequence of corners clicked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the correspondences, we can estimate the P matrix. Implement the DLT function that returns the P matrix\n",
    "\n",
    "Quick recap: x_i = P * X_i where (x_i, X_i) is the ith correspondence, and P is a 3x4 dimensional matrix. P is further decomposed as P = K * [ R | T].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theory\n",
    "\n",
    "- Explain how DLT is implemented and show why it works (proof)\n",
    "- When does DLT fail?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing P\n",
    "\n",
    "The next part of this question is to analyse how good our estimate is. Report the reprojection error of your P matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the P matrix, we can estimate K, R and T. Write a function that returns K,R,T given P.\n",
    "Note: \n",
    "P = K * [R | T] where K is a 3x3 matrix and [R | T], P are 3x4 matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verifying the R, K, T Values\n",
    "\n",
    "Use `np.isclose` to verify the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reproject the world points with P matrix you have obtained via DLT and visualize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zhangs method\n",
    "\n",
    "For this task, use the inbuilt Opencv function to estimate the K matrix of a camera. Use the checkerboard images 5456-5470 in `q1/zhangs` folder for this task. Familiarize yourself with the different parameters for this method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reference**: https://docs.opencv.org/3.4/dc/dbb/tutorial_py_calibration.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 4.2 Epipolar lines\n",
    "#### Task 1\n",
    "\n",
    "For this task, you have been given two images of the same scene taken from different view-points. You should first estimate the fundamental matrix from these two images.\n",
    "\n",
    "<img src=\"./q2/img1.jpg\" alt=\"image 1\" width=\"400\"/>\n",
    "<img src=\"./q2/img2.jpg\" alt=\"image 2\" width=\"400\"/>\n",
    "\n",
    "\n",
    "Recall that given a point in one image, it's corresponding location in the other image can be found to along a line viz. the epipolar line. The task given to you is to draw the epipolar lines in the second image for each given point in the first image. You have to repeat this for the other image as well. Draw epipolar lines on the first image for the corresponding points in the second image.\n",
    "\n",
    "The convention used for F is $x'^{T}Fx$ where $x'$ is the location of the point in the second image. For this question you will need to compute the F matrix on your own without using inbuilt functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib tk\n",
    "\n",
    "def get_points_byclick(file:str, points_arr:list):\n",
    "    fig = plt.figure(figsize=(20, 30))\n",
    "\n",
    "    img = mpimg.imread(file)\n",
    "\n",
    "\n",
    "    def onclick(event):\n",
    "        ix, iy = event.xdata, event.ydata\n",
    "        points_arr.append([ix, iy])\n",
    "\n",
    "\n",
    "    cid = fig.canvas.mpl_connect('button_press_event', onclick)\n",
    "\n",
    "    imgplot = plt.imshow(img)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "colors = np.random.rand(10)\n",
    "def display_points_on_img(file:str, image_points):\n",
    "    N = len(image_points)\n",
    "    image_points = np.array(image_points)\n",
    "    fig = plt.figure(figsize=(10, 15))\n",
    "\n",
    "    img = mpimg.imread(file)\n",
    "    imgplot = plt.imshow(img)\n",
    "\n",
    "    \n",
    "    area = (15 * np.ones(N))**2\n",
    "\n",
    "    plt.scatter(image_points[:, 0], image_points[:, 1], c=colors[:N], s=area)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### init data (does not work, separate into blocks)\n",
    "# %matplotlib tk \n",
    "# points_1 = []\n",
    "# get_points_byclick('q2/img1.jpg', points_1)\n",
    "# input()\n",
    "# points_2 = []\n",
    "# get_points_byclick('q2/img2.jpg', points_2)\n",
    "# input()\n",
    "# %matplotlib inline\n",
    "# display_points_on_img('q2/img1.jpg', points_1)\n",
    "# display_points_on_img('q2/img2.jpg', points_2)\n",
    "# with open('data.txt', 'w+') as f:\n",
    "#     f.write(str(points_1) + '\\n')\n",
    "#     f.write(str(points_2) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### data prerecorded\n",
    "points_1 = np.array( \n",
    "    [[371.2357565035582, 96.69271440633668], [491.8581681476417, 105.37752804471063], [610.5506212054199, 134.3269068392907], [721.5232399179765, 172.92607856539746], [\n",
    "        666.5194202082746, 378.4666680069157], [650.1147722246792, 469.1747215632665], [426.23957621326036, 516.4587069277472], [324.91675043223023, 318.63795183145027]]\n",
    ")\n",
    "\n",
    "points_2 = np.array( \n",
    "    [[385.71044590084824, 106.34250733786337], [469.66364440513036, 72.56823207751995], [577.7413252382291, 49.40872904185596], [701.2586747617706, 37.82897752402391], [\n",
    "        639.4999999999998, 255.91429777652684], [620.2004141369466, 346.62235133287766], [420.4497004543443, 434.43546700977043], [354.8311085199629, 295.4784487957862]]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Points selected are:  \n",
    "<img src=\"./q2_img1.png\" alt=\"image 1\" width=\"400\"/>\n",
    "<img src=\"./q2_img2.png\" alt=\"image 2\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_sol(points1, points2):\n",
    "    def vectorize_point(x, xd):\n",
    "        x1, y1 = x\n",
    "        x1d, y1d = xd\n",
    "        return [ \n",
    "            x1d*x1,\n",
    "            x1d*y1, \n",
    "            x1d, \n",
    "            y1d*x1,\n",
    "            y1d*y1, \n",
    "            y1d, \n",
    "            x1, \n",
    "            y1, \n",
    "            1\n",
    "        ]\n",
    "    \n",
    "    A = np.array([],dtype=np.float64)\n",
    "    for x,xd in zip(points1, points2):\n",
    "        A = np.concatenate((A, vectorize_point(x,xd)))\n",
    "    A = A.reshape(-1, 9)\n",
    "\n",
    "    u,d,v = np.linalg.svd(A)\n",
    "    return v[:, -1].reshape(3,3)\n",
    "\n",
    "\n",
    "def contraint_enforcement(f):\n",
    "    u,d,v = np.linalg.svd(f)\n",
    "    newd = np.diag([d[0], d[1], 0])\n",
    "\n",
    "    return u@newd@v\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.70187938e-09  3.97651555e-08  7.17021767e-06]\n",
      " [ 3.29706320e-05  2.54445804e-03 -3.15540902e-03]\n",
      " [-5.47790609e-04  2.96993985e-03  9.99987224e-01]]\n"
     ]
    }
   ],
   "source": [
    "f = linear_sol(points_1, points_2)\n",
    "f_hat = contraint_enforcement(f)\n",
    "\n",
    "print(f_hat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Provide a clear explanation on your approach for both this task and the next**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2\n",
    "Report the location of the epipoles. Mathematically find the epipoles and verify that the lines intersect at the epipole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "### 4.3 Drawing a bounding box around a car and localizing it in the camera frame\n",
    "You’ve been provided with an image, also taken from a self-driving car, that shows another car in front. The camera has been placed on top of the car, 1.65 m from the ground, and assume the image plane is perfectly perpendicular to the ground. K is provided to you. Your task is to draw a 3D-bounding box around the car in front as shown. Your approach should be to place eight points in the 3D world such that they surround all the corners of the car, then project them onto the image, and connect the projected image points using lines. You might have to apply a small 5° rotation about the vertical axis to align the box perfectly. Rough dimensions of the car - h: 1.38 m, w: 1.51, l: 4.10. (Hint: Fix a point on the ground as your world origin.). Also estimate the approximate translation vector to the mid-point of the two rear wheels of the car in the camera frame.\n",
    "\n",
    "![Kitti car](./q3/image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
