{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mexican-confirmation",
   "metadata": {},
   "source": [
    "# Question 4: General Theory/Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-cleaners",
   "metadata": {},
   "source": [
    "_No need to be verbose, it's not fun for anyone_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-hindu",
   "metadata": {},
   "source": [
    "1. What part of S**L**A**M** did this project deal with? Why? What does the other part deal with and how would it generally work, given that you only have LIDAR scans, RGB video stream, and noisy pose data for a moving robot?\n",
    "\n",
    "\n",
    "2. Loop closures play an important role in reducing drift, how would you go about detecting these?\n",
    "\n",
    "\n",
    "3. Explain the structure of your Jacobian. Is the pose-graph fully connected? Why/Why not?\n",
    "\n",
    "\n",
    "4. With what you know now, how would you describe and differentiate the SLAM frontend and backend? Why do we need to optimise our poses/map in the first place - where does the noise come from/why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abstract-bones",
   "metadata": {},
   "source": [
    "### Answer\n",
    "1. This project dealt with Localization part of the S**L**AM, because we optimized the poses of the robot in the project. The other part of the SLAM invloves mapping, which can be solved using the landmark pose graph or the ICP SLAM. Given the LIDAR readings, we would perform point cloud registration on them and then we would optimize the tranjectory transformations and the poses both wrt the RGB and LIDAR readings.\n",
    "\n",
    "\n",
    "2. Loop detection can be done using feature mapping and there are alsomany deeplearning based algorithms to detect loops in pose-graphs.  \n",
    "\n",
    "3. The Jacobian is calculated by stacking partial derivatives wrt to all the parameters to be optimized. In current scenario, the parameters are the (x,y,theta) of all the poses of the robot.\n",
    "\n",
    "    $\\mathbf{J}=\\frac{\\partial \\mathbf{f}}{\\partial \\mathbf{X}}=\\left(\\frac{\\partial \\mathbf{f}}{\\partial \\mathbf{x}_{0}} \\frac{\\partial \\mathbf{f}}{\\partial \\mathbf{x}_{1}} \\cdots \\frac{\\partial \\mathbf{f}}{\\partial \\mathbf{x}_{n}}\\right)$\n",
    "- Shape: `contraints_cnt` $\\times$ `vars_cnt`, where  \n",
    "    - `contraints_cnt` = (1 + edges_cnt)*3 \n",
    "    - `vars_cnt` = poses_cnt * 3\n",
    "\n",
    "The Pose-Graph is not fully connected because we have not considered loops between all the pairs of poses, but we have considered only among nearby poses. We have 139 edges but 120 poses.\n",
    "\n",
    "4. \n",
    "- Frontend: This part of SLAM deals with the sensor readings and it generates the pose-graph for SLAM. This part involves doing work like point cloud registration from LIDAR, calculating poses from odometry, calculating transformation from ICP, loop-detections for pose-graph, etc. which would finally generate a pose-graph according to the problem statement which would then be optimized by the backend.\n",
    "- Backend: This part receives a pose-graph from the frontend and optimizes it to have the best estimate of the mapping of the surroundings and the current pose and trajectory of the robot. It may uses algorithms like least-squares algorithm to optimize the given graph.\n",
    "\n",
    "\n",
    "There is a need to optimize the pose-graph because sensor readings have a noise when readings are taken in the real physical world. We can not only rely on certain sensors for knowing the path of the robot and need to consider al the related sensor readings to have a best estimate of the mapping and localization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
